
 === Running with l = 100 ===
#Eigenvalues / Matrix_dimension: 100 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 297, Converged = 1, ‖r‖ (largest λ) = 2.1805377919175595e-12
Iter 5: V_size = 197, Converged = 1, ‖r‖ (largest λ) = 2.3488011121636324e-12
Iter 6: V_size = 150, Converged = 25, ‖r‖ (largest λ) = 2.0382177387180522e-12
Iter 7: V_size = 225, Converged = 25, ‖r‖ (largest λ) = 1.138025827081192e-7
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 7.242173656159439e-10
Iter 9: V_size = 64, Converged = 68, ‖r‖ (largest λ) = 1.200814585763506e-10
Iter 10: V_size = 96, Converged = 68, ‖r‖ (largest λ) = 5.337844445476077e-7
Iter 11: V_size = 128, Converged = 68, ‖r‖ (largest λ) = 4.70907387814617e-8
Iter 12: V_size = 2, Converged = 99, ‖r‖ (largest λ) = 7.1848625471564975e-9
Iter 13: V_size = 3, Converged = 99, ‖r‖ (largest λ) = 9.8630356498767e-5
Iter 14: V_size = 4, Converged = 99, ‖r‖ (largest λ) = 0.00011362967234008226
Converged all eigenvalues.
 44.216568 seconds (1.94 M allocations: 59.453 GiB, 3.45% gc time)
Total estimated FLOPs: 787724524380

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×100 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.54747e-12  -4.20641e-12  1.53477e-12  2.78533e-12  5.96856e-13  1.02318e-12  4.26326e-13  7.10543e-14  1.13687e-13  1.42109e-13  -2.62901e-13  6.39488e-14  -4.9738e-14  -3.55271e-14  -1.84741e-13  -1.77636e-14  3.55271e-14  -5.32907e-14  -1.1724e-13  -3.90799e-14  9.59233e-14  -5.50671e-14  1.33227e-13  1.59872e-14  -1.06581e-14  1.77636e-14  -5.86198e-14  0.0  1.77636e-15  2.4869e-14  1.5099e-14  2.39808e-14  8.88178e-16  1.06581e-14  2.66454e-15  3.55271e-15  -1.59872e-14  -8.88178e-15  -6.21725e-15  -2.66454e-15  -1.77636e-15  -1.42109e-14  1.77636e-15  1.33227e-15  4.44089e-16  8.43769e-15  5.77316e-15  5.77316e-15  8.88178e-15  1.04361e-13  9.28146e-14  8.43769e-15  7.54952e-15  7.10543e-15  1.73195e-14  3.33067e-14  1.02141e-14  8.21565e-14  6.61693e-14  2.63345e-13  3.45945e-13  7.82485e-13  1.64069e-12  2.9714e-12  4.95515e-12  2.639e-12  3.72369e-12  4.21885e-15  -3.33067e-15  -2.66454e-15  -1.33227e-15  8.88178e-16  1.9984e-15  -1.77636e-15  3.55271e-15  1.70974e-14  8.08242e-14  7.06102e-14  3.19744e-14  4.70735e-14  1.4766e-13  4.8257e-12  2.86016e-12  1.3789e-12  2.76534e-12  3.56914e-12  5.85754e-12  2.40821e-11  8.31812e-12  3.8e-11  8.6039e-11  1.6724e-10  6.36557e-10  2.72121e-10  2.34674e-9  1.11172e-9  2.0229e-8  1.49176e-8  1.18216e-7
100 Eigenvalues converges, out of 100 requested.

 === Running with l = 200 ===
#Eigenvalues / Matrix_dimension: 200 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.358005027620246e-12
Iter 5: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.860980955431401e-12
Iter 6: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 2.2406821519366327e-12
Iter 7: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 1.5957140312110277e-8
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 1.6789096629978763e-10
Iter 9: V_size = 242, Converged = 79, ‖r‖ (largest λ) = 1.1944022788259705e-10
Iter 10: V_size = 242, Converged = 79, ‖r‖ (largest λ) = 5.430164450206612e-7
Iter 11: V_size = 242, Converged = 79, ‖r‖ (largest λ) = 5.119236577790079e-8
Iter 12: V_size = 144, Converged = 128, ‖r‖ (largest λ) = 4.990137584049073e-9
Iter 13: V_size = 216, Converged = 128, ‖r‖ (largest λ) = 2.2105580670616827e-5
Iter 14: V_size = 288, Converged = 128, ‖r‖ (largest λ) = 7.648096780079529e-7
Iter 15: V_size = 90, Converged = 155, ‖r‖ (largest λ) = 9.252267264572627e-8
Iter 16: V_size = 135, Converged = 155, ‖r‖ (largest λ) = 1.567105638763892e-6
Iter 17: V_size = 180, Converged = 155, ‖r‖ (largest λ) = 3.266820343172776e-7
Iter 18: V_size = 12, Converged = 194, ‖r‖ (largest λ) = 2.764920046476524e-7
Iter 19: V_size = 18, Converged = 194, ‖r‖ (largest λ) = 3.662154480623679e-5
Iter 20: V_size = 24, Converged = 194, ‖r‖ (largest λ) = 2.0657637676208924e-5
Converged all eigenvalues.
104.316241 seconds (8.12 M allocations: 247.334 GiB, 4.18% gc time)
Total estimated FLOPs: 1734636599840

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×200 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.77485e-12  -3.75167e-12  1.53477e-12  2.67164e-12  7.10543e-13  1.02318e-12  3.69482e-13  2.84217e-13  7.10543e-14  2.98428e-13  -1.84741e-13  1.27898e-13  -1.63425e-13  -6.39488e-14  -8.52651e-14  1.20792e-13  2.16716e-13  -2.84217e-14  1.3145e-13  1.56319e-13  -1.06581e-14  5.68434e-14  1.06581e-14  1.74083e-13  -3.55271e-15  3.01981e-14  -7.10543e-14  8.88178e-15  1.24345e-14  2.30926e-14  7.10543e-15  1.5099e-14  -1.77636e-15  1.77636e-15  -2.04281e-14  0.0  -1.68754e-14  -1.77636e-15  5.32907e-15  -7.10543e-15  3.55271e-15  -1.06581e-14  -8.88178e-16  2.66454e-15  5.77316e-15  7.10543e-15  1.33227e-15  3.10862e-15  8.88178e-15  1.02141e-13  8.92619e-14  1.33227e-14  4.44089e-15  2.66454e-15  8.88178e-16  -8.88178e-16  -3.10862e-15  3.10862e-15  3.10862e-15  3.9968e-15  5.77316e-15  1.9984e-14  3.08642e-14  3.24185e-14  6.57252e-14  3.93019e-14  8.4821e-14  4.01679e-13  6.9833e-13  6.39933e-13  8.38885e-13  2.28084e-12  3.33644e-12  1.94333e-12  7.50533e-12  1.84093e-11  -4.44089e-16  2.22045e-15  1.15195e-11  2.06815e-11  1.11022e-15  1.77636e-15  -8.88178e-16  4.44089e-16  3.55271e-15  2.88658e-15  -4.44089e-16  2.22045e-15  8.88178e-16  5.55112e-15  8.88178e-15  1.28786e-14  3.16414e-14  2.35367e-14  7.21645e-14  1.3245e-13  1.38556e-13  9.15934e-14  6.17506e-13  5.4512e-13  1.05305e-12  7.05769e-13  5.27201e-12  1.44338e-11  2.07723e-12  3.96139e-12  8.67617e-12  1.89037e-11  1.26622e-11  1.48468e-11  2.56076e-11  1.18574e-11  8.47595e-11  1.83349e-10  1.7534e-10  1.21536e-10  8.12533e-10  3.75124e-10  1.01999e-9  5.87092e-10  1.1641e-9  1.32977e-9  1.24997e-9  2.09712e-9  3.07672e-9  3.33488e-9  2.63539e-9  1.78191e-14  1.09912e-14  1.53766e-14  1.69864e-14  2.4647e-14  9.14269e-14  4.85167e-14  6.7113e-14  6.53366e-14  2.03115e-13  2.15439e-13  2.96818e-13  4.90052e-13  1.1714e-12  6.50979e-13  3.72546e-12  4.17266e-12  1.64041e-12  3.73745e-12  3.63942e-12  1.07663e-11  6.87833e-12  2.06222e-11  1.04868e-11  1.18102e-11  4.82073e-11  -3.16802e-13  6.79543e-11  -1.57208e-13  -7.71605e-14  -1.61815e-13  -1.95066e-13  -3.58602e-14  -8.64864e-14  -4.26881e-14  -2.86438e-14  -9.51295e-13  -8.50098e-13  -3.07199e-13  -3.20444e-12  -9.36917e-13  -7.83817e-13  2.23066e-12  1.77047e-12  6.89171e-13  1.20243e-12  2.01428e-12  4.94516e-12  2.47691e-11  2.75937e-11  3.16823e-11  7.54292e-11  2.29474e-10  1.18105e-10  2.20264e-10  4.2332e-10  5.64677e-10  4.94177e-10  1.6168e-9  2.224e-9  3.23949e-9  5.33377e-9  7.4982e-9  6.57116e-9  6.52489e-9  2.69608e-9  1.3367e-8  4.28403e-9  8.08162e-10  8.77696e-9  2.42879e-8  3.23189e-8
200 Eigenvalues converges, out of 200 requested.

 === Running with l = 300 ===
#Eigenvalues / Matrix_dimension: 300 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.358005027620246e-12
Iter 5: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.808085436085621e-12
Iter 6: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 2.588760905530742e-12
Iter 7: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.1742085292623625e-6
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.0018860103662434e-8
Iter 9: V_size = 300, Converged = 54, ‖r‖ (largest λ) = 3.489954874632765e-10
Iter 10: V_size = 300, Converged = 54, ‖r‖ (largest λ) = 0.00012063083481691449
Iter 11: V_size = 300, Converged = 54, ‖r‖ (largest λ) = 4.389525904249467e-6
Iter 12: V_size = 300, Converged = 68, ‖r‖ (largest λ) = 1.3022923585348029e-6
Iter 13: V_size = 300, Converged = 68, ‖r‖ (largest λ) = 1.2356323619998253e-5
Iter 14: V_size = 300, Converged = 68, ‖r‖ (largest λ) = 1.2353355166620937e-5
Iter 15: V_size = 300, Converged = 108, ‖r‖ (largest λ) = 1.235333680182949e-5
Iter 16: V_size = 300, Converged = 108, ‖r‖ (largest λ) = 6.114902972456304e-5
Iter 17: V_size = 300, Converged = 108, ‖r‖ (largest λ) = 6.113557537647805e-5
Iter 18: V_size = 300, Converged = 136, ‖r‖ (largest λ) = 6.113530772959269e-5
Iter 19: V_size = 300, Converged = 136, ‖r‖ (largest λ) = 3.827944007637728e-5
Iter 20: V_size = 300, Converged = 136, ‖r‖ (largest λ) = 3.682799114415473e-5
Iter 21: V_size = 210, Converged = 195, ‖r‖ (largest λ) = 3.678078361485316e-5
Iter 22: V_size = 210, Converged = 195, ‖r‖ (largest λ) = 9.10938425444234e-5
Iter 23: V_size = 210, Converged = 195, ‖r‖ (largest λ) = 8.788594146404266e-5
Iter 24: V_size = 156, Converged = 222, ‖r‖ (largest λ) = 8.737894861329649e-5
Iter 25: V_size = 234, Converged = 222, ‖r‖ (largest λ) = 8.905429865352444e-5
Iter 26: V_size = 156, Converged = 222, ‖r‖ (largest λ) = 5.4683419745039864e-5
Iter 27: V_size = 118, Converged = 241, ‖r‖ (largest λ) = 5.448089407220817e-5
Iter 28: V_size = 177, Converged = 241, ‖r‖ (largest λ) = 0.00011370265304182216
Iter 29: V_size = 236, Converged = 241, ‖r‖ (largest λ) = 0.00011358126428298975
Iter 30: V_size = 48, Converged = 276, ‖r‖ (largest λ) = 0.00011357745028604982
Iter 31: V_size = 72, Converged = 276, ‖r‖ (largest λ) = 9.254043125973873e-5
Iter 32: V_size = 96, Converged = 276, ‖r‖ (largest λ) = 8.346276614523567e-5
Iter 33: V_size = 20, Converged = 290, ‖r‖ (largest λ) = 8.204083077238928e-5
Iter 34: V_size = 30, Converged = 290, ‖r‖ (largest λ) = 0.0001219704247162573
Iter 35: V_size = 40, Converged = 290, ‖r‖ (largest λ) = 0.00010511811676107943
Iter 36: V_size = 10, Converged = 295, ‖r‖ (largest λ) = 9.418159337458101e-5
Iter 37: V_size = 15, Converged = 295, ‖r‖ (largest λ) = 0.00016722202916523662
Iter 38: V_size = 20, Converged = 295, ‖r‖ (largest λ) = 0.00015261036604067994
Iter 39: V_size = 4, Converged = 298, ‖r‖ (largest λ) = 0.00018072995078798876
Iter 40: V_size = 6, Converged = 298, ‖r‖ (largest λ) = 0.00018638778855456148
Iter 41: V_size = 8, Converged = 298, ‖r‖ (largest λ) = 0.00018429464638141873
Converged all eigenvalues.
247.847418 seconds (25.76 M allocations: 779.911 GiB, 4.51% gc time)
Total estimated FLOPs: 3870708028340

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×300 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.54747e-12  -4.09273e-12  1.76215e-12  2.44427e-12  5.11591e-13  9.37916e-13  3.55271e-13  5.68434e-14  2.27374e-13  1.56319e-13  0.0  1.49214e-13  -1.77636e-13  -7.10543e-15  -1.45661e-13  7.10543e-14  -1.06581e-14  0.0  -4.9738e-14  -3.55271e-14  1.52767e-13  -2.91323e-13  -1.24345e-13  -1.24345e-13  -2.13163e-14  3.37508e-14  -6.21725e-14  3.55271e-15  1.59872e-14  7.10543e-15  7.99361e-15  1.42109e-14  7.10543e-15  8.88178e-15  1.77636e-15  5.32907e-15  -1.59872e-14  -1.59872e-14  8.88178e-16  -6.21725e-15  -1.06581e-14  -2.66454e-15  -8.88178e-16  4.44089e-15  1.33227e-15  3.86358e-14  1.59872e-14  1.7053e-13  1.53211e-13  1.47171e-7  5.37802e-7  5.05386e-7  1.82986e-6  -1.48295e-11  -8.01448e-12  -1.09846e-10  -9.46354e-12  -1.70512e-10  -1.71076e-11  -1.95848e-11  -2.94387e-12  -8.70779e-11  -2.16824e-11  -6.65956e-11  -1.45065e-10  -1.25386e-11  -1.7091e-10  -1.23383e-10  -2.64957e-10  -6.98338e-10  -9.13525e-11  -4.82679e-10  -1.93278e-10  -4.85646e-10  -7.05172e-10  -7.41178e-11  -3.11771e-11  -1.28165e-10  -2.10812e-10  -4.3212e-10  -4.67308e-11  -1.54071e-9  -4.36861e-10  -1.68711e-9  -6.95074e-10  -1.12083e-10  -6.00453e-10  -8.32849e-11  -1.36364e-10  -2.45817e-10  -1.55011e-9  -2.54693e-9  -2.93886e-10  -3.37636e-10  -1.43118e-10  -6.8181e-12  -2.14974e-9  -1.94468e-9  -8.76731e-10  -1.25535e-9  -3.2989e-10  -3.32694e-9  -1.8354e-9  -6.23339e-10  -1.7335e-10  -1.45247e-9  -4.32981e-10  -1.6426e-9  -2.63738e-10  -7.45815e-10  -1.44745e-9  -1.80767e-10  -3.31069e-11  -1.18868e-10  -4.04557e-10  -9.578e-10  -2.93735e-10  -4.35519e-10  -1.57711e-9  -6.24447e-10  -2.20359e-9  -7.24552e-10  -5.49601e-10  -1.68441e-9  -5.28551e-10  -2.24876e-10  -1.59359e-9  -3.44416e-9  -2.4623e-10  -3.12421e-11  -2.17775e-9  -1.14904e-9  -3.24875e-9  -3.75024e-10  -7.50367e-10  -5.64698e-10  -1.18588e-9  -3.84144e-9  -4.48522e-10  -5.12671e-9  -6.51717e-9  -4.63918e-9  -4.05759e-9  -9.43761e-9  -8.8347e-9  -2.91632e-9  -1.75104e-9  -7.63481e-9  -1.18949e-9  -1.76767e-10  -3.54191e-9  -5.64221e-9  -1.05032e-9  -2.46283e-10  -4.09951e-9  -4.57021e-9  -2.57094e-9  -1.35945e-8  -1.07069e-8  -1.77369e-9  -1.46886e-8  -9.07134e-9  -1.66776e-9  -5.4301e-9  -6.07495e-9  -3.49637e-8  -2.15362e-9  -2.73688e-8  -8.70678e-9  -2.51069e-9  -1.17335e-8  -8.90873e-11  -5.86603e-9  3.80531e-10  -3.10405e-9  1.11734e-9  -1.28998e-8  -6.10024e-9  -2.60984e-9  -2.00798e-9  -2.83812e-8  3.19789e-9  -1.29152e-9  -7.14715e-9  3.68379e-9  -5.2607e-9  -6.54108e-9  8.11346e-9  -8.10458e-10  9.96465e-9  1.35315e-8  5.40019e-9  -2.74073e-9  1.67098e-8  1.28584e-8  -5.54939e-10  -3.35116e-10  -4.10267e-9  -4.67323e-9  -1.48619e-9  -1.96158e-9  -3.58205e-9  -6.75713e-9  -1.86473e-9  6.20162e-12  3.52695e-9  -1.40433e-9  -5.8238e-9  1.77674e-9  1.67597e-10  2.41915e-9  2.81722e-9  4.94267e-9  7.53645e-9  1.31528e-8  3.03473e-8  5.60505e-8  3.24039e-8  4.2423e-8  5.51945e-8  7.41255e-8  -1.1057e-9  -1.49244e-9  -2.12331e-10  -2.03342e-9  -2.29167e-9  -6.29733e-9  -2.08744e-9  -1.35945e-9  -4.03997e-11  -1.02303e-9  -4.34799e-9  -3.39351e-9  -2.89106e-9  -1.96397e-9  -1.92794e-9  -7.43047e-9  -5.82115e-12  -1.57164e-9  -4.87643e-9  -1.26098e-10  -8.68906e-10  -2.16411e-9  -3.71098e-9  -3.65663e-9  -1.15112e-9  -2.49862e-9  -2.49997e-10  -1.83967e-9  -6.03076e-9  -2.77587e-9  -2.13929e-9  -5.53152e-10  -1.86165e-9  -1.90266e-9  -7.0717e-10  -1.35383e-9  7.48334e-10  -6.66529e-10  -1.89789e-9  3.85592e-10  -6.36657e-11  -2.19025e-10  3.57558e-9  1.03284e-8  2.26357e-9  6.62232e-9  5.25436e-9  9.77972e-10  1.6857e-8  2.31361e-8  1.15777e-8  1.68617e-8  3.50815e-8  8.78376e-10  3.58171e-8  5.30914e-9  4.65457e-8  1.84607e-8  3.0824e-8  3.11697e-8  4.32782e-8  9.19502e-8  1.32247e-7  6.93905e-8  2.85963e-7  3.265e-7  4.5582e-7  1.74968e-7  3.25923e-7  3.43496e-7  3.36264e-7  7.37174e-7  1.33719e-6  1.20679e-6  1.12066e-6  5.13379e-6  2.91211e-6  7.615e-6
300 Eigenvalues converges, out of 300 requested.

 === Running with l = 400 ===
#Eigenvalues / Matrix_dimension: 400 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.358005027620246e-12
Iter 5: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.8745865838698482e-12
Iter 6: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.3088608507510778e-12
Iter 7: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458480712e-6
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458488656e-6
Iter 9: V_size = 256, Converged = 197, ‖r‖ (largest λ) = 3.3910704584855894e-6
Iter 10: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.0069998435211375935
Iter 11: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004206413561378072
Iter 12: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004196481842185709
Iter 13: V_size = 300, Converged = 207, ‖r‖ (largest λ) = 0.004196357704327248
Iter 14: V_size = 300, Converged = 207, ‖r‖ (largest λ) = 0.011161567757401595
Iter 15: V_size = 300, Converged = 207, ‖r‖ (largest λ) = 0.011161579230656906
Iter 16: V_size = 254, Converged = 273, ‖r‖ (largest λ) = 0.011161585750499707
Iter 17: V_size = 254, Converged = 273, ‖r‖ (largest λ) = 0.025981650728745084
Iter 18: V_size = 254, Converged = 273, ‖r‖ (largest λ) = 0.025981613048236554
Iter 19: V_size = 176, Converged = 312, ‖r‖ (largest λ) = 0.02598155156026477
Iter 20: V_size = 264, Converged = 312, ‖r‖ (largest λ) = 0.018834905724425848
Iter 21: V_size = 176, Converged = 312, ‖r‖ (largest λ) = 0.018834099751898453
Iter 22: V_size = 138, Converged = 331, ‖r‖ (largest λ) = 0.018834136009598948
Iter 23: V_size = 207, Converged = 331, ‖r‖ (largest λ) = 0.015729178784980993
Iter 24: V_size = 276, Converged = 331, ‖r‖ (largest λ) = 0.015729336059964304
Iter 25: V_size = 60, Converged = 370, ‖r‖ (largest λ) = 0.015729868002357955
Iter 26: V_size = 90, Converged = 370, ‖r‖ (largest λ) = 0.012046807357904412
Iter 27: V_size = 120, Converged = 370, ‖r‖ (largest λ) = 0.01204780817142512
Iter 28: V_size = 26, Converged = 387, ‖r‖ (largest λ) = 0.012048310616875946
Iter 29: V_size = 39, Converged = 387, ‖r‖ (largest λ) = 0.010953157825792158
Iter 30: V_size = 52, Converged = 387, ‖r‖ (largest λ) = 0.010951750156663732
Iter 31: V_size = 10, Converged = 395, ‖r‖ (largest λ) = 0.010951848407237766
Iter 32: V_size = 15, Converged = 395, ‖r‖ (largest λ) = 0.009305608437228653
Iter 33: V_size = 20, Converged = 395, ‖r‖ (largest λ) = 0.009300999092587635
Iter 34: V_size = 6, Converged = 397, ‖r‖ (largest λ) = 0.009289846116588644
Iter 35: V_size = 9, Converged = 397, ‖r‖ (largest λ) = 0.010373153430307492
Iter 36: V_size = 12, Converged = 397, ‖r‖ (largest λ) = 0.010369006484296853
Iter 37: V_size = 4, Converged = 398, ‖r‖ (largest λ) = 0.01036797262672011
Iter 38: V_size = 6, Converged = 398, ‖r‖ (largest λ) = 0.010940112047389565
Iter 39: V_size = 8, Converged = 398, ‖r‖ (largest λ) = 0.010899200885937937
Iter 40: V_size = 10, Converged = 398, ‖r‖ (largest λ) = 0.010846358855604704
Iter 41: V_size = 12, Converged = 398, ‖r‖ (largest λ) = 0.010475350004264201
Iter 42: V_size = 14, Converged = 398, ‖r‖ (largest λ) = 0.010148413960176872
Iter 43: V_size = 16, Converged = 398, ‖r‖ (largest λ) = 0.009957508807467328
Iter 44: V_size = 18, Converged = 398, ‖r‖ (largest λ) = 0.009915735311300147
Iter 45: V_size = 20, Converged = 398, ‖r‖ (largest λ) = 0.00990497831101096
Iter 46: V_size = 2, Converged = 399, ‖r‖ (largest λ) = 0.009890249546332736
Iter 47: V_size = 3, Converged = 399, ‖r‖ (largest λ) = 0.009883986771889453
Iter 48: V_size = 4, Converged = 399, ‖r‖ (largest λ) = 0.009876217841117705
Iter 49: V_size = 5, Converged = 399, ‖r‖ (largest λ) = 0.009871249799960466
Iter 50: V_size = 6, Converged = 399, ‖r‖ (largest λ) = 0.009868030736658222
Iter 51: V_size = 7, Converged = 399, ‖r‖ (largest λ) = 0.009866570191041493
Iter 52: V_size = 8, Converged = 399, ‖r‖ (largest λ) = 0.009859459507364828
Iter 53: V_size = 9, Converged = 399, ‖r‖ (largest λ) = 0.009855491100373483
Iter 54: V_size = 10, Converged = 399, ‖r‖ (largest λ) = 0.009851565351087535
Iter 55: V_size = 11, Converged = 399, ‖r‖ (largest λ) = 0.009841327057288969
Converged all eigenvalues.
233.449277 seconds (27.72 M allocations: 844.073 GiB, 4.54% gc time)
Total estimated FLOPs: 3322486364200

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×400 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.54747e-12  -5.45697e-12  1.02318e-12  2.16005e-12  4.54747e-13  8.81073e-13  3.12639e-13  1.42109e-13  1.42109e-13  2.13163e-13  -7.81597e-14  7.81597e-14  -6.39488e-14  2.13163e-14  -5.68434e-14  1.06581e-14  2.84217e-14  4.26326e-14  4.9738e-14  2.13163e-14  -6.39488e-14  -3.73035e-14  2.84217e-14  -5.32907e-15  9.9476e-13  1.31095e-12  1.94866e-12  3.5083e-12  3.68594e-12  1.90621e-11  7.40741e-12  1.79332e-11  1.22098e-11  7.30829e-11  2.71791e-11  4.19718e-11  9.56453e-11  4.94698e-10  7.02842e-11  5.43554e-10  9.44181e-10  2.97297e-9  4.19487e-9  1.17408e-9  1.81322e-9  1.65756e-8  4.38371e-9  1.05013e-7  4.85183e-7  6.41839e-7  1.51316e-6  8.37174e-7  2.71936e-6  1.62762e-5  2.04923e-5  6.1245e-5  1.88645e-5  0.000162179  6.1576e-5  0.000136342  0.000242666  0.000135921  0.000541141  0.0003779  0.000531745  0.000359323  0.00075586  0.00172693  0.00133116  0.0013997  0.00167353  -6.67674e-5  -2.65224e-5  -1.00294e-5  -2.66656e-5  -2.03213e-5  3.51342e-6  -1.15644e-5  0.00252707  -3.06644e-5  -1.17828e-5  -0.000175064  -0.000112923  -2.22378e-5  -1.26448e-5  -1.30496e-5  -1.73864e-5  1.08838e-5  6.58902e-7  1.00872e-6  4.49071e-6  2.36403e-5  5.93242e-5  3.92731e-5  4.34932e-5  0.000120407  4.39819e-5  0.000124517  4.52638e-5  0.000117746  0.000179919  5.02665e-5  0.00064482  0.00071304  0.000170941  0.000260333  0.000368589  0.000273299  0.000411462  0.000337399  0.000335204  0.000217781  0.000436027  0.00120024  0.000458821  0.00066654  0.00112234  0.000469151  0.000764208  0.000857761  0.000767417  0.000750821  0.00127598  0.000917733  0.000744277  0.00087182  0.00115653  0.00162349  0.00141052  0.00117763  0.00151587  0.00137808  0.00202762  0.00158564  0.00157445  0.00107077  0.00186014  0.000901474  0.00151843  0.00136373  0.0015555  0.0011702  0.0018721  0.00181747  0.00175604  0.00188519  0.00186479  0.00121696  0.00195805  0.00166462  0.00154935  0.00164138  0.00215103  0.00190894  0.00124199  0.00180197  0.00203846  0.00252847  0.00164614  0.00121703  0.00132469  0.00261519  0.00144264  0.00127094  0.001961  0.00190759  0.00200809  0.00234975  0.00191255  0.00119163  0.00123202  0.00158687  0.0016106  0.0019762  0.00207956  0.0010144  0.00161817  0.00124562  0.00130842  0.00123087  0.00141095  0.00211169  0.00168098  0.001383  0.00105283  0.00124694  0.00169376  0.00135477  0.00148765  0.00171684  0.00170446  0.00234536  0.00182444  0.00207384  0.00139447  0.00113131  0.0014035  0.0013364  0.00119677  0.00170282  0.000986411  0.00119432  0.00087534  0.00094529  0.00110651  0.00132712  0.00125027  0.000989033  0.00129557  0.00125312  0.00109181  0.000933006  0.000973234  0.00154106  0.00148941  0.00163621  0.000941211  0.00121667  0.00143834  0.00119552  0.00102181  0.000781227  0.00127027  0.000928705  0.00118889  0.00122094  0.0010151  0.00113988  0.00127617  0.00129458  0.00101437  0.00117355  0.00106764  0.00175483  0.00155807  0.00117977  0.00169389  0.00139404  0.00199884  0.00163517  0.00112561  0.00118532  0.00141719  0.00127099  0.00136017  0.000891131  0.00133697  0.00138525  0.000694362  0.000902153  0.000922583  0.00119472  0.00121797  0.00122652  0.000993811  0.000983671  0.00134845  0.000635909  0.00118777  0.0012417  0.00138879  0.00119823  0.000896133  0.000950001  0.000534917  0.000601609  0.00154214  0.00104824  0.00128099  0.000980047  0.000928313  0.000738776  0.00124593  0.00131876  0.00142308  0.0589799  0.0601497  0.0603122  0.059767  0.0601356  0.0595897  0.0594431  0.0594482  0.058939  0.0586482  0.0583322  0.0575479  0.0570153  0.056797  0.0566913  0.0564456  0.0564796  0.0560887  0.0555981  0.0555453  0.0554787  0.0550206  0.0551786  0.0554229  0.05596  0.0556395  0.0580226  0.0652474  0.0665435  0.0672147  0.0679038  0.0676961  0.068101  0.0692207  0.0698011  0.0706121  0.0709074  0.0712449  0.0716335  0.0725395  0.0739004  0.0745912  0.0754638  0.0759526  0.0764734  0.0793612  0.0801707  0.0812475  0.0821867  0.0823102  0.083332  0.0833935  0.0841261  0.083961  0.0836361  0.0836328  0.0842604  0.0842538  0.0844361  0.0844322  0.0845836  0.0843542  0.0843294  0.0843221  0.0838628  0.0839754  0.0838301  0.0837009  0.0836774  0.0836451  0.0834896  0.0834236  0.0832642  0.0832251  0.0833491  0.0830834  0.0829436  0.0831422  0.0830097  0.0828278  0.0828395  0.0829791  0.0833112  0.0834931  0.0837789  0.0842871  0.0852363  0.0860951  0.0865445  0.0868173  0.0879553  0.0894294  0.0898681  0.0913682  0.0916969  0.0921326  0.0957044  0.0982477  0.0992088  0.118906  0.123012  0.123594  0.123581  0.123739  0.123818  0.123794  0.123877  0.123898  0.123777  0.124335  0.124061  0.123969  0.123932  0.123988  0.12408  0.124034  0.124043  0.124075  0.12432  0.12449  0.124503  0.124625  0.124776  0.124934
400 Eigenvalues converges, out of 400 requested.

 === Running with l = 500 ===
#Eigenvalues / Matrix_dimension: 500 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.358005027620246e-12
Iter 5: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.8745865838698482e-12
Iter 6: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.3088608507510778e-12
Iter 7: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458480712e-6
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458488656e-6
Iter 9: V_size = 256, Converged = 197, ‖r‖ (largest λ) = 3.3910704584855894e-6
Iter 10: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.006999843521137609
Iter 11: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004213419169151729
Iter 12: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004213419169151746
Iter 13: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.004213419169151743
Iter 14: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.0290006643932662
Iter 15: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027741968022139667
Iter 16: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027717143007876952
Iter 17: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027715734903099098
Iter 18: V_size = 294, Converged = 353, ‖r‖ (largest λ) = 0.027715819158260782
Iter 19: V_size = 294, Converged = 353, ‖r‖ (largest λ) = 0.03205073764714354
Iter 20: V_size = 294, Converged = 353, ‖r‖ (largest λ) = 0.03205087788880226
Iter 21: V_size = 196, Converged = 402, ‖r‖ (largest λ) = 0.03205114601972191
Iter 22: V_size = 294, Converged = 402, ‖r‖ (largest λ) = 0.02674074428457855
Iter 23: V_size = 196, Converged = 402, ‖r‖ (largest λ) = 0.026740368361268783
Iter 24: V_size = 142, Converged = 429, ‖r‖ (largest λ) = 0.026740999301580064
Iter 25: V_size = 213, Converged = 429, ‖r‖ (largest λ) = 0.02144996721159823
Iter 26: V_size = 284, Converged = 429, ‖r‖ (largest λ) = 0.021449893059388058
Iter 27: V_size = 66, Converged = 467, ‖r‖ (largest λ) = 0.02145078222071546
Iter 28: V_size = 99, Converged = 467, ‖r‖ (largest λ) = 0.015708510239427414
Iter 29: V_size = 132, Converged = 467, ‖r‖ (largest λ) = 0.01570774011185865
Iter 30: V_size = 30, Converged = 485, ‖r‖ (largest λ) = 0.015709910686400003
Iter 31: V_size = 45, Converged = 485, ‖r‖ (largest λ) = 0.014110087446562905
Iter 32: V_size = 60, Converged = 485, ‖r‖ (largest λ) = 0.014108998811267098
Iter 33: V_size = 16, Converged = 492, ‖r‖ (largest λ) = 0.014109114977403685
Iter 34: V_size = 24, Converged = 492, ‖r‖ (largest λ) = 0.01607134109921494
Iter 35: V_size = 32, Converged = 492, ‖r‖ (largest λ) = 0.016071175264088706
Iter 36: V_size = 8, Converged = 496, ‖r‖ (largest λ) = 0.016061365957261754
Iter 37: V_size = 12, Converged = 496, ‖r‖ (largest λ) = 0.01491767281094223
Iter 38: V_size = 16, Converged = 496, ‖r‖ (largest λ) = 0.014900878450233917
Iter 39: V_size = 6, Converged = 497, ‖r‖ (largest λ) = 0.014888378600181827
Iter 40: V_size = 9, Converged = 497, ‖r‖ (largest λ) = 0.014893129847201767
Iter 41: V_size = 4, Converged = 498, ‖r‖ (largest λ) = 0.01487008957301296
Iter 42: V_size = 6, Converged = 498, ‖r‖ (largest λ) = 0.012941931050086683
Iter 43: V_size = 8, Converged = 498, ‖r‖ (largest λ) = 0.012912841132720508
Iter 44: V_size = 10, Converged = 498, ‖r‖ (largest λ) = 0.012830591582931882
Iter 45: V_size = 12, Converged = 498, ‖r‖ (largest λ) = 0.012625006718856543
Iter 46: V_size = 14, Converged = 498, ‖r‖ (largest λ) = 0.012551973016154629
Iter 47: V_size = 16, Converged = 498, ‖r‖ (largest λ) = 0.012526608783044414
Iter 48: V_size = 18, Converged = 498, ‖r‖ (largest λ) = 0.012525438711586217
Iter 49: V_size = 20, Converged = 498, ‖r‖ (largest λ) = 0.012529535664456293
Iter 50: V_size = 22, Converged = 498, ‖r‖ (largest λ) = 0.012526373506353824
Iter 51: V_size = 24, Converged = 498, ‖r‖ (largest λ) = 0.012529975994404268
Iter 52: V_size = 2, Converged = 499, ‖r‖ (largest λ) = 0.012527505788475191
Iter 53: V_size = 3, Converged = 499, ‖r‖ (largest λ) = 0.013404302063472777
Iter 54: V_size = 4, Converged = 499, ‖r‖ (largest λ) = 0.013384371841676027
Iter 55: V_size = 5, Converged = 499, ‖r‖ (largest λ) = 0.013371664211633607
Iter 56: V_size = 6, Converged = 499, ‖r‖ (largest λ) = 0.01334837654257596
Iter 57: V_size = 7, Converged = 499, ‖r‖ (largest λ) = 0.013328874055142517
Converged all eigenvalues.
305.057068 seconds (38.30 M allocations: 1.141 TiB, 4.80% gc time)
Total estimated FLOPs: 3832154186680

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×500 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.54747e-12  -5.45697e-12  1.02318e-12  2.16005e-12  4.54747e-13  8.81073e-13  3.12639e-13  1.42109e-13  1.42109e-13  2.13163e-13  -7.81597e-14  7.81597e-14  -6.39488e-14  2.13163e-14  -5.68434e-14  1.06581e-14  2.84217e-14  4.26326e-14  4.9738e-14  2.13163e-14  -6.39488e-14  -3.73035e-14  2.84217e-14  -5.32907e-15  9.9476e-13  1.31095e-12  1.94866e-12  3.5083e-12  3.68594e-12  1.90621e-11  7.40741e-12  1.79332e-11  1.22098e-11  7.30829e-11  2.71791e-11  4.19718e-11  9.56453e-11  4.94698e-10  7.02842e-11  5.43554e-10  9.44181e-10  2.97297e-9  4.19487e-9  1.17408e-9  1.81322e-9  1.65756e-8  4.38371e-9  1.05013e-7  4.85183e-7  6.41839e-7  1.51316e-6  8.37174e-7  2.71936e-6  1.62762e-5  2.04923e-5  6.1245e-5  1.88645e-5  0.000162179  6.1576e-5  0.000136342  0.000242666  0.000135921  0.000541141  0.0003779  0.000531745  0.000359323  0.00075586  0.00172693  0.00133116  0.0013997  0.00167353  -6.66623e-5  -2.6426e-5  -9.97546e-6  -2.63984e-5  -2.00261e-5  4.13808e-6  -1.10369e-5  0.00252707  -3.01729e-5  -1.12422e-5  -0.000169953  -0.000110652  -1.9656e-5  -8.29306e-6  -1.15253e-5  -1.25927e-5  1.4702e-5  2.39172e-6  8.22367e-6  1.00067e-5  3.19551e-5  7.36117e-5  5.43949e-5  7.55271e-5  0.00014202  8.75108e-5  0.000155572  9.56753e-5  0.000155957  0.000356908  8.74061e-5  0.00093628  0.00123632  0.0003224  0.000367972  0.000571059  0.000583702  0.000680709  0.000664296  0.00065293  0.000333711  0.00113549  0.00236274  0.00156905  0.00149244  0.00288984  0.00183184  0.0051716  0.00400306  0.00299493  0.00509338  0.0046132  0.00364265  0.00335877  0.0037757  0.00429818  0.00639992  0.00200071  0.00506951  0.00791134  0.00649414  0.000988705  0.00109791  0.000710204  0.000856238  0.00377377  0.00555656  0.0012135  -0.00120166  0.00106765  0.00082701  0.000371309  0.00150238  0.00154041  0.00183531  0.00190897  0.000783049  0.00202435  0.00175199  0.00101451  0.00177695  0.00200535  0.00182328  0.00155834  0.00178739  0.00196346  0.00257635  0.00210385  0.00124361  0.00182969  0.00313804  0.00159851  0.00160836  0.00236372  0.00234921  0.00227702  0.00325887  0.00213759  0.00191056  0.00142052  0.00266374  0.00202364  0.00256851  0.00323678  0.00158858  0.00235794  0.00259693  0.00229552  0.00286317  0.00213584  0.00316737  0.00294252  0.0022204  0.00281075  0.00239945  0.00306534  0.00268392  0.00259928  0.00310369  0.00309081  0.00371021  0.00435766  0.00350187  0.00296686  0.00235411  0.00280339  0.00267427  0.00265131  0.00293506  0.00219278  0.00264201  0.00253637  0.00280895  0.00290487  0.00342285  0.00354109  0.0027564  0.00268793  0.00310788  0.00272933  0.00269042  0.00278819  0.00327984  0.0032333  0.00337919  0.00256493  0.0029776  0.00323506  0.00239939  0.0026918  0.00265883  0.00340116  0.00325259  0.00265814  0.00240077  0.00268471  0.00265245  0.00337341  0.00323924  0.00245202  0.00300399  0.00389227  0.00339428  0.00292637  0.00263362  0.0041968  0.00394993  0.00349804  0.00334128  0.00328313  0.00339213  0.00317337  0.00347783  0.0030706  0.00295358  0.00347513  0.00291512  0.00262922  0.00197296  0.0018679  0.00241512  0.00257296  0.00294272  0.00300616  0.00246406  0.00254401  0.00220651  0.00357877  0.00306412  0.00351301  0.00312194  0.00269641  0.00236651  0.00220535  0.00184454  0.00250121  0.00287468  0.00260545  0.00266695  0.00267666  0.00234877  0.00318883  0.00269756  0.00286953  0.00283714  0.00308746  0.00256367  0.00249023  0.00253024  0.00210632  0.00269561  0.00283873  0.00223959  0.00217997  0.00207454  0.00227119  0.00213821  0.0268148  0.028361  0.0310195  0.0355925  0.0361011  0.0459131  0.0478725  0.0476961  0.0482589  0.0488742  0.049104  0.0494124  0.048322  0.0484079  0.0487392  0.0487698  0.0485802  0.0482184  0.0478446  0.0472341  0.0470434  0.0473793  0.046491  0.0464411  0.0469566  0.0468609  0.0466117  0.046372  0.0464668  0.0466849  0.046875  0.0471251  0.0477542  0.0500708  0.0552009  0.0568494  0.0578119  0.0587195  0.0595237  0.0594901  0.0604109  0.0611157  0.0613832  0.0629338  0.0631789  0.0636487  0.0640243  0.0650549  0.064825  0.066265  0.0672011  0.0677874  0.0683594  0.0692763  0.0721388  0.0730588  0.0740637  0.0753638  0.0755909  0.0765589  0.0768252  0.0777139  0.0774816  0.0775342  0.0777377  0.0783684  0.0781249  0.0780725  0.0777771  0.0779052  0.0780207  0.0782165  0.0783602  0.0783395  0.0782942  0.0780613  0.0779671  0.0780322  0.0776366  0.0775992  0.0775253  0.0773544  0.0775199  0.0775669  0.0773704  0.0773901  0.0774182  0.0773562  0.0774427  0.0773852  0.0773467  0.0771796  0.0774623  0.0774322  0.0772773  0.0770925  0.0773082  0.0772794  0.0770593  0.0771125  0.0771923  0.0774921  0.0774272  0.0775861  0.0779812  0.0779664  0.0783797  0.0782921  0.0781915  0.0784569  0.0784618  0.0787007  0.0786724  0.0790076  0.079591  0.0793866  0.0798734  0.079883  0.0800562  0.0800454  0.0802596  0.0801621  0.0807395  0.0807149  0.0807834  0.0810833  0.0811456  0.0814651  0.0818232  0.0818734  0.0821654  0.082255  0.0824227  0.0824983  0.082494  0.0828236  0.0831594  0.0833901  0.0836857  0.0838719  0.0840741  0.0840386  0.0843771  0.0844389  0.0845397  0.0849515  0.0848849  0.0852544  0.0853783  0.0856415  0.0858327  0.0862221  0.0861812  0.0867276  0.0868939  0.0868586  0.0873354  0.0877426  0.0880789  0.0880905  0.0883323  0.0891572  0.0893201  0.0895336  0.089606  0.0898038  0.0902738  0.090378  0.0911306  0.0911913  0.0912341  0.0921049  0.0925484  0.092883  0.0929163  0.0937515  0.0940517  0.0952815  0.0958499  0.0962748  0.0965795  0.0974359  0.102051  0.10858  0.110272  0.110945  0.1128  0.114358  0.115093  0.115168  0.115465  0.115716  0.115713  0.115799  0.115962  0.115998  0.11658  0.116577  0.116703  0.116776  0.116973  0.117071  0.117176  0.117245  0.117362  0.117651  0.117907  0.118091  0.118308  0.118567  0.118827
500 Eigenvalues converges, out of 500 requested.

 === Running with l = 600 ===
#Eigenvalues / Matrix_dimension: 600 / 12000
read large_sparse_matrix.dat
Davidson
Iter 1: V_size = 50, Converged = 0, ‖r‖ (largest λ) = 0.04433324667685322
Iter 2: V_size = 100, Converged = 0, ‖r‖ (largest λ) = 3.7867364314173698e-6
Iter 3: V_size = 198, Converged = 1, ‖r‖ (largest λ) = 6.351422325117998e-10
Iter 4: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.358005027620246e-12
Iter 5: V_size = 300, Converged = 1, ‖r‖ (largest λ) = 2.8745865838698482e-12
Iter 6: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.3088608507510778e-12
Iter 7: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458480712e-6
Iter 8: V_size = 300, Converged = 25, ‖r‖ (largest λ) = 3.391070458488656e-6
Iter 9: V_size = 256, Converged = 197, ‖r‖ (largest λ) = 3.3910704584855894e-6
Iter 10: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.006999843521137609
Iter 11: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004213419169151729
Iter 12: V_size = 300, Converged = 197, ‖r‖ (largest λ) = 0.004213419169151746
Iter 13: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.004213419169151743
Iter 14: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.029000664393266203
Iter 15: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027752632559847674
Iter 16: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027718368277190653
Iter 17: V_size = 300, Converged = 344, ‖r‖ (largest λ) = 0.027716332041432763
Iter 18: V_size = 300, Converged = 350, ‖r‖ (largest λ) = 0.027716495019427016
Iter 19: V_size = 300, Converged = 350, ‖r‖ (largest λ) = 0.03683799531533977
Iter 20: V_size = 300, Converged = 350, ‖r‖ (largest λ) = 0.036838103493391824
Iter 21: V_size = 300, Converged = 388, ‖r‖ (largest λ) = 0.0368381355577514
Iter 22: V_size = 300, Converged = 388, ‖r‖ (largest λ) = 0.02732594728342044
Iter 23: V_size = 300, Converged = 388, ‖r‖ (largest λ) = 0.027325361564736955
Iter 24: V_size = 300, Converged = 400, ‖r‖ (largest λ) = 0.02732593447587878
Iter 25: V_size = 300, Converged = 400, ‖r‖ (largest λ) = 0.02389271881420907
Iter 26: V_size = 300, Converged = 400, ‖r‖ (largest λ) = 0.023892681403626242
Iter 27: V_size = 300, Converged = 433, ‖r‖ (largest λ) = 0.023893373240420783
Iter 28: V_size = 300, Converged = 433, ‖r‖ (largest λ) = 0.021651139419045517
Iter 29: V_size = 300, Converged = 433, ‖r‖ (largest λ) = 0.02165222064750581
Iter 30: V_size = 272, Converged = 464, ‖r‖ (largest λ) = 0.021652435488827074
Iter 31: V_size = 272, Converged = 464, ‖r‖ (largest λ) = 0.01571218482345098
Iter 32: V_size = 272, Converged = 464, ‖r‖ (largest λ) = 0.01571289346585668
Iter 33: V_size = 238, Converged = 481, ‖r‖ (largest λ) = 0.01571263727015118
Iter 34: V_size = 238, Converged = 481, ‖r‖ (largest λ) = 0.014764878442556705
Iter 35: V_size = 238, Converged = 481, ‖r‖ (largest λ) = 0.014764755075160157
Iter 36: V_size = 204, Converged = 498, ‖r‖ (largest λ) = 0.01476498397976477
Iter 37: V_size = 204, Converged = 498, ‖r‖ (largest λ) = 0.012612180450329165
Iter 38: V_size = 204, Converged = 498, ‖r‖ (largest λ) = 0.012609985302010226
Iter 39: V_size = 178, Converged = 511, ‖r‖ (largest λ) = 0.012609190533071971
Iter 40: V_size = 267, Converged = 511, ‖r‖ (largest λ) = 0.011976233890700358
Iter 41: V_size = 178, Converged = 511, ‖r‖ (largest λ) = 0.011976660665967597
Iter 42: V_size = 160, Converged = 520, ‖r‖ (largest λ) = 0.011987607798522317
Iter 43: V_size = 240, Converged = 520, ‖r‖ (largest λ) = 0.013001369672398325
Iter 44: V_size = 160, Converged = 520, ‖r‖ (largest λ) = 0.013004146965576283
Iter 45: V_size = 110, Converged = 545, ‖r‖ (largest λ) = 0.013009662384996358
Iter 46: V_size = 165, Converged = 545, ‖r‖ (largest λ) = 0.014712502805665313
Iter 47: V_size = 220, Converged = 545, ‖r‖ (largest λ) = 0.014713093441002066
Iter 48: V_size = 76, Converged = 562, ‖r‖ (largest λ) = 0.014715285191432463
Iter 49: V_size = 114, Converged = 562, ‖r‖ (largest λ) = 0.01233146141470885
Iter 50: V_size = 152, Converged = 562, ‖r‖ (largest λ) = 0.012332159272921701
Iter 51: V_size = 40, Converged = 580, ‖r‖ (largest λ) = 0.012366645649418884
Iter 52: V_size = 60, Converged = 580, ‖r‖ (largest λ) = 0.009381801194791456
Iter 53: V_size = 80, Converged = 580, ‖r‖ (largest λ) = 0.009375467255145629
Iter 54: V_size = 26, Converged = 587, ‖r‖ (largest λ) = 0.009364368797620325
Iter 55: V_size = 39, Converged = 587, ‖r‖ (largest λ) = 0.007700988539039284
Iter 56: V_size = 52, Converged = 587, ‖r‖ (largest λ) = 0.007695852727194746
Iter 57: V_size = 22, Converged = 589, ‖r‖ (largest λ) = 0.007690235198134971
Iter 58: V_size = 33, Converged = 589, ‖r‖ (largest λ) = 0.007602126483362022
Iter 59: V_size = 44, Converged = 589, ‖r‖ (largest λ) = 0.007588811603110357
Iter 60: V_size = 16, Converged = 592, ‖r‖ (largest λ) = 0.007570684390906368
Iter 61: V_size = 24, Converged = 592, ‖r‖ (largest λ) = 0.007447881817731027
Iter 62: V_size = 32, Converged = 592, ‖r‖ (largest λ) = 0.007434051686138812
Iter 63: V_size = 4, Converged = 598, ‖r‖ (largest λ) = 0.007430016262273227
Iter 64: V_size = 6, Converged = 598, ‖r‖ (largest λ) = 0.008570500952518727
Iter 65: V_size = 8, Converged = 598, ‖r‖ (largest λ) = 0.008531219345663326
Converged all eigenvalues.
590.563617 seconds (81.70 M allocations: 2.417 TiB, 4.96% gc time)
Total estimated FLOPs: 6696055573140

Reading exact Eigenvalues...
Reading eigenvalues from test_EW_results.jld2

Difference between Davidson and exact eigenvalues:
1×600 adjoint(::Vector{Float64}) with eltype Float64:
 -1.27329e-11  4.54747e-12  -5.45697e-12  1.02318e-12  2.16005e-12  4.54747e-13  8.81073e-13  3.12639e-13  1.42109e-13  1.42109e-13  2.13163e-13  -7.81597e-14  7.81597e-14  -6.39488e-14  2.13163e-14  -5.68434e-14  1.06581e-14  2.84217e-14  4.26326e-14  4.9738e-14  2.13163e-14  -6.39488e-14  -3.73035e-14  2.84217e-14  -5.32907e-15  9.9476e-13  1.31095e-12  1.94866e-12  3.5083e-12  3.68594e-12  1.90621e-11  7.40741e-12  1.79332e-11  1.22098e-11  7.30829e-11  2.71791e-11  4.19718e-11  9.56453e-11  4.94698e-10  7.02842e-11  5.43554e-10  9.44181e-10  2.97297e-9  4.19487e-9  1.17408e-9  1.81322e-9  1.65756e-8  4.38371e-9  1.05013e-7  4.85183e-7  6.41839e-7  1.51316e-6  8.37174e-7  2.71936e-6  1.62762e-5  2.04923e-5  6.1245e-5  1.88645e-5  0.000162179  6.1576e-5  0.000136342  0.000242666  0.000135921  0.000541141  0.0003779  0.000531745  0.000359323  0.00075586  0.00172693  0.00133116  0.0013997  0.00167353  -6.66623e-5  -2.6426e-5  -9.97546e-6  -2.63984e-5  -2.00261e-5  4.13808e-6  -1.10369e-5  0.00252707  -3.01729e-5  -1.12422e-5  -0.000169953  -0.000110652  -1.9656e-5  -8.29306e-6  -1.15253e-5  -1.25927e-5  1.4702e-5  2.39172e-6  8.22367e-6  1.00067e-5  3.19551e-5  7.36117e-5  5.43949e-5  7.55271e-5  0.00014202  8.75108e-5  0.000155572  9.56753e-5  0.000155957  0.000356908  8.74061e-5  0.00093628  0.00123632  0.0003224  0.000367972  0.000571059  0.000583702  0.000680709  0.000664296  0.00065293  0.000333711  0.00113549  0.00236274  0.00156905  0.00149244  0.00288984  0.00183184  0.0051716  0.00400306  0.00299493  0.00509338  0.0046132  0.00364265  0.00335877  0.0037757  0.00429818  0.00639992  0.00200071  0.00506951  0.00791134  0.0064941  0.000988705  0.00109789  0.00071018  0.000856262  0.00377373  0.00555656  0.00121349  -0.00120173  0.00106768  0.00082705  0.000371289  0.00150243  0.00154034  0.00183527  0.00190899  0.000783054  0.00202438  0.00175204  0.00101441  0.00177696  0.00200533  0.00182316  0.00155834  0.00178721  0.00196351  0.0025764  0.00210384  0.00124347  0.00182965  0.00313811  0.00159849  0.00160841  0.0023637  0.00234918  0.00227711  0.00325888  0.00213754  0.00191057  0.00142058  0.00266379  0.00202365  0.00256836  0.00323667  0.00158852  0.00235754  0.00259677  0.0022953  0.00286299  0.00213529  0.00316713  0.00294237  0.00222025  0.00281068  0.00239936  0.00306499  0.00268341  0.00259915  0.0031032  0.00309096  0.00371035  0.00435793  0.00350177  0.00296704  0.00235426  0.00280347  0.00267415  0.00265109  0.00293506  0.00219277  0.00264222  0.00253637  0.00280852  0.00290489  0.00342316  0.00354108  0.00275651  0.00268803  0.00310821  0.00272955  0.00269044  0.00278798  0.00327988  0.00323354  0.00337929  0.00256486  0.00297774  0.00323477  0.00239955  0.00269158  0.00265899  0.00340165  0.00325216  0.00265766  0.00240039  0.00268475  0.00265239  0.00337292  0.00323918  0.00245213  0.00300375  0.00389201  0.00339421  0.00292657  0.00263374  0.00419726  0.00395054  0.00349815  0.00334126  0.0032844  0.00339239  0.00317346  0.00347837  0.0030713  0.00295434  0.0034759  0.00291537  0.00263045  0.0019729  0.00186896  0.0024162  0.00257331  0.00294405  0.00300676  0.00246427  0.0025442  0.0022072  0.00357899  0.00306427  0.00351371  0.00312299  0.00269717  0.002368  0.00220876  0.00184473  0.00250216  0.00287521  0.00260586  0.00266836  0.00267685  0.00234931  0.0031897  0.00269713  0.00287019  0.00283852  0.00308856  0.00256383  0.00248896  0.00253119  0.00210915  0.00269281  0.00283496  0.00223689  0.00217094  0.00206717  0.00226834  0.00211987  0.0024167  0.00231621  0.00264376  0.00290926  0.00198879  0.00201385  0.00252657  0.00246626  0.00242164  0.00207675  0.0024646  0.00295978  0.00201502  0.00216221  0.00232078  0.00238128  0.00240937  0.00248693  0.00242552  0.00220559  0.00247942  0.00248927  0.00197425  0.00214509  0.00203618  0.00209297  0.00233626  0.00247381  0.00227444  0.00245747  0.00240309  0.00245236  0.00243882  0.00277402  0.00262554  0.00215714  0.00226868  0.00223232  0.00236714  0.00221038  0.00216561  0.00174517  0.00148788  0.00168634  0.00197422  0.0021477  0.00210162  0.00199251  0.00182171  0.00208459  0.00222662  0.00190884  0.00191962  0.00191475  0.00177882  0.00222463  0.00204688  0.00189636  0.00177808  0.00188069  0.0020575  0.00232067  0.00216092  0.00200262  0.00201719  0.00191258  0.0017197  0.00164455  0.00145007  0.00148048  0.00165661  0.00159636  0.00159401  0.00188471  0.00165589  0.00160724  0.00165219  0.00154462  0.00134384  0.00116651  0.00126208  0.00108305  0.00127062  0.00141997  0.0010751  0.00126287  0.00125074  0.00137766  0.00130006  0.00118614  0.00129987  0.00121068  0.00127295  0.00137277  0.00131024  0.00127736  0.00146359  0.00121336  0.00118309  0.00117665  0.00112993  0.0012223  0.00123262  0.00517686  0.00671227  0.017092  0.0191231  0.0189455  0.0204503  0.0214151  0.0217154  0.0222605  0.0223238  0.0223972  0.0231599  0.0230948  0.0232885  0.0233227  0.023338  0.0233564  0.023349  0.0236753  0.023798  0.0237196  0.0243592  0.0244653  0.0245154  0.024609  0.0251399  0.0256231  0.0260102  0.0267418  0.0276225  0.0300679  0.0354611  0.0376351  0.0390195  0.0400609  0.0410524  0.0412796  0.0424449  0.043695  0.0443061  0.0461713  0.0466  0.0471193  0.0476215  0.0487996  0.0489639  0.0504264  0.0515554  0.0528072  0.0534747  0.0545734  0.0576754  0.0586636  0.0599802  0.0614792  0.0620071  0.0631621  0.0635479  0.0645688  0.0646369  0.0648914  0.0652982  0.0660215  0.0660808  0.0663024  0.0663008  0.0664836  0.066678  0.0669912  0.0671531  0.0672519  0.067466  0.0675683  0.0676291  0.0678918  0.0679032  0.068006  0.0680116  0.0680498  0.0683244  0.0684012  0.068644  0.0686766  0.0687028  0.0687023  0.0689417  0.0689723  0.069072  0.0690775  0.0693808  0.0693542  0.0693413  0.069313  0.0695534  0.0697957  0.0697934  0.069957  0.0701774  0.0704829  0.0705694  0.0707887  0.0712684  0.0712978  0.0717964  0.0718795  0.0718745  0.0722481  0.0723547  0.0726454  0.0726032  0.0731294  0.0736897  0.0736896  0.0741921  0.0742547  0.0744685  0.0746533  0.0748505  0.0748508  0.0754755  0.0756438  0.0757412  0.0760718  0.076149  0.0765303  0.0769279  0.0771144  0.0774414  0.0776407  0.0778011  0.0779492  0.0779636  0.0783514  0.0786439  0.0788842  0.079341  0.0795374  0.079803  0.0797698  0.0801835  0.080254  0.0803855  0.0807762  0.0808112  0.0812545  0.0813977  0.0817484  0.0819703  0.0823873  0.0824204  0.0829373  0.0831309  0.0831511  0.0836502  0.0840805  0.0844058  0.0844533  0.0847114  0.0855094  0.085759  0.0860093  0.0860422  0.0862799  0.0868421  0.0869206  0.0876737  0.0877872  0.0878162  0.0887382  0.089214  0.0895312  0.089599  0.0904995  0.0907585  0.0919874  0.0925873  0.0930508  0.0933879  0.0942358  0.0988934  0.10539  0.107121  0.107797  0.109639  0.111224  0.111929  0.112091  0.112396  0.11263  0.112636  0.112796  0.112934  0.113006  0.113574  0.113587  0.113694  0.113796  0.113985  0.114109  0.114214  0.114326  0.114435  0.114718  0.114957  0.1152  0.115388  0.115656  0.115946
600 Eigenvalues converges, out of 600 requested.
